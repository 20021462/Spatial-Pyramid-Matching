{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eirlSPSU-Z4g"
      },
      "outputs": [],
      "source": [
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob"
      ],
      "metadata": {
        "id": "HgqEHp1ILxXv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [name[11:] for name in glob.glob('data/train/*')]\n",
        "class_names = dict(zip(range(0,len(class_names)), class_names))\n",
        "print (class_names)\n",
        "\n",
        "def load_dataset(path, num_per_class=-1):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for id, class_name in class_names.items():\n",
        "        img_path_class = glob.glob(path + class_name + '/*.jpg')\n",
        "        if num_per_class > 0:\n",
        "            img_path_class = img_path_class[:num_per_class]\n",
        "        labels.extend([id]*len(img_path_class))\n",
        "        for filename in img_path_class:\n",
        "            data.append(cv2.imread(filename, 0))\n",
        "    return data, labels\n",
        "\n",
        "# load training dataset\n",
        "train_data, train_label = load_dataset('data/train/', 100)\n",
        "train_num = len(train_label)\n",
        "\n",
        "# load testing dataset\n",
        "test_data, test_label = load_dataset('data/test/', 100)\n",
        "test_num = len(test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8-PGPg3L2IP",
        "outputId": "9bacb70d-2550-4c09-f51f-7e82e2280280"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Office', 1: 'Coast', 2: 'Bedroom', 3: 'LivingRoom', 4: 'Forest', 5: 'Street', 6: 'Industrial', 7: 'Highway', 8: 'Mountain', 9: 'InsideCity', 10: 'Suburb', 11: 'OpenCountry', 12: 'Store', 13: 'Kitchen'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute dense SIFT\n",
        "def computeSIFT(data):\n",
        "    x = []\n",
        "    for i in range(0, len(data)):\n",
        "        sift = cv2.xfeatures2d.SIFT_create()\n",
        "        img = data[i]\n",
        "        step_size = 15\n",
        "        kp = [cv2.KeyPoint(x, y, step_size) for x in range(0, img.shape[0], step_size) for y in range(0, img.shape[1], step_size)]\n",
        "        dense_feat = sift.compute(img, kp)\n",
        "        x.append(dense_feat[1])\n",
        "\n",
        "    return x\n",
        "\n",
        "# extract dense sift features from training images\n",
        "x_train = computeSIFT(train_data)\n",
        "x_test = computeSIFT(test_data)\n",
        "\n",
        "all_train_desc = []\n",
        "for i in range(len(x_train)):\n",
        "    for j in range(x_train[i].shape[0]):\n",
        "        all_train_desc.append(x_train[i][j,:])\n",
        "\n",
        "all_train_desc = np.array(all_train_desc)"
      ],
      "metadata": {
        "id": "qDRjv9LYzOHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def clusterFeatures(all_train_desc, k):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0).fit(all_train_desc)\n",
        "    return kmeans"
      ],
      "metadata": {
        "id": "Tmkc4KbJzCKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 200\n",
        "kmeans = clusterFeatures(all_train_desc, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1QKVf5IsGrE",
        "outputId": "69091a41-5c9b-4818-e63e-14a1398de2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def extract_denseSIFT(img):\n",
        "    DSIFT_STEP_SIZE = 2\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    disft_step_size = DSIFT_STEP_SIZE\n",
        "    keypoints = [cv2.KeyPoint(x, y, disft_step_size)\n",
        "            for y in range(0, img.shape[0], disft_step_size)\n",
        "                for x in range(0, img.shape[1], disft_step_size)]\n",
        "\n",
        "    descriptors = sift.compute(img, keypoints)[1]\n",
        "    return descriptors\n",
        "\n",
        "\n",
        "# form histogram with Spatial Pyramid Matching upto level L with codebook kmeans and k codewords\n",
        "def getImageFeaturesSPM(L, img, kmeans, k):\n",
        "    W = img.shape[1]\n",
        "    H = img.shape[0]\n",
        "    h = []\n",
        "    for l in range(L+1):\n",
        "        w_step = math.floor(W/(2**l))\n",
        "        h_step = math.floor(H/(2**l))\n",
        "        x, y = 0, 0\n",
        "        for i in range(1,2**l + 1):\n",
        "            x = 0\n",
        "            for j in range(1, 2**l + 1):\n",
        "                desc = extract_denseSIFT(img[y:y+h_step, x:x+w_step])\n",
        "                #print(\"type:\",desc is None, \"x:\",x,\"y:\",y, \"desc_size:\",desc is None)\n",
        "                predict = kmeans.predict(desc)\n",
        "                histo = np.bincount(predict, minlength=k).reshape(1,-1).ravel()\n",
        "                weight = 2**(l-L)\n",
        "                h.append(weight*histo)\n",
        "                x = x + w_step\n",
        "            y = y + h_step\n",
        "\n",
        "    hist = np.array(h).ravel()\n",
        "    # normalize hist\n",
        "    dev = np.std(hist)\n",
        "    hist -= np.mean(hist)\n",
        "    hist /= dev\n",
        "    return hist\n",
        "\n",
        "\n",
        "# get histogram representation for training/testing data\n",
        "def getHistogramSPM(L, data, kmeans, k):\n",
        "    x = []\n",
        "    for i in range(len(data)):\n",
        "        hist = getImageFeaturesSPM(L, data[i], kmeans, k)\n",
        "        x.append(hist)\n",
        "    return np.array(x)"
      ],
      "metadata": {
        "id": "_Dr0dS1VsFFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_histo = getHistogramSPM(2, train_data, kmeans, k)\n",
        "test_histo = getHistogramSPM(2, test_data, kmeans, k)"
      ],
      "metadata": {
        "id": "FiqfQ4F1_QqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "for c in np.arange(0.000307, 0.001, 0.0000462):\n",
        "    clf = LinearSVC(random_state=0, C=c)\n",
        "    clf.fit(train_histo, train_label)\n",
        "    predict = clf.predict(test_histo)\n",
        "    print (\"C =\", c, \",\\t\\t Accuracy:\", np.mean(predict == test_label)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqE71qCAq3qQ",
        "outputId": "7397a05f-5324-43c7-9dc2-07b25631bf09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C = 0.000307 ,\t\t Accuracy: 69.85714285714286 %\n",
            "C = 0.00035319999999999997 ,\t\t Accuracy: 69.64285714285714 %\n",
            "C = 0.00039939999999999995 ,\t\t Accuracy: 69.71428571428572 %\n",
            "C = 0.00044559999999999993 ,\t\t Accuracy: 70.07142857142857 %\n",
            "C = 0.0004917999999999999 ,\t\t Accuracy: 70.07142857142857 %\n",
            "C = 0.0005379999999999998 ,\t\t Accuracy: 70.14285714285714 %\n",
            "C = 0.0005841999999999999 ,\t\t Accuracy: 70.0 %\n",
            "C = 0.0006303999999999999 ,\t\t Accuracy: 69.78571428571428 %\n",
            "C = 0.0006765999999999999 ,\t\t Accuracy: 69.92857142857143 %\n",
            "C = 0.0007227999999999998 ,\t\t Accuracy: 70.0 %\n",
            "C = 0.0007689999999999998 ,\t\t Accuracy: 70.0 %\n",
            "C = 0.0008151999999999999 ,\t\t Accuracy: 70.07142857142857 %\n",
            "C = 0.0008613999999999998 ,\t\t Accuracy: 69.92857142857143 %\n",
            "C = 0.0009075999999999997 ,\t\t Accuracy: 69.78571428571428 %\n",
            "C = 0.0009537999999999998 ,\t\t Accuracy: 69.71428571428572 %\n",
            "C = 0.0009999999999999998 ,\t\t Accuracy: 69.57142857142857 %\n"
          ]
        }
      ]
    }
  ]
}